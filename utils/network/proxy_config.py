# utils/network/proxy_config.py
# ä»£ç†é…ç½®æ¨¡å—ï¼ŒåŒ…å«è‡ªåŠ¨æ£€æµ‹Windowsç³»ç»Ÿä»£ç†ã€æ¨ç‰¹éªŒè¯å’Œé™çº§å¤„ç†

import winreg
import requests
import logging
import time
from typing import Optional, Dict, Any


# å…¨å±€ä»£ç†é…ç½®
_global_proxy = None

# Twitterå¯ç”¨æ€§çŠ¶æ€
_twitter_accessible = True


def get_system_proxy() -> Optional[Dict[str, str]]:
    """
    è‡ªåŠ¨æ£€æµ‹Windowsç³»ç»Ÿä»£ç†è®¾ç½®
    Returns:
        Dict[str, str] or None: ä»£ç†é…ç½®å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        # æ‰“å¼€æ³¨å†Œè¡¨é¡¹
        reg_key = winreg.OpenKey(
            winreg.HKEY_CURRENT_USER,
            r"Software\Microsoft\Windows\CurrentVersion\Internet Settings"
        )
        
        try:
            # æ£€æŸ¥ä»£ç†æ˜¯å¦å¯ç”¨
            proxy_enable, _ = winreg.QueryValueEx(reg_key, "ProxyEnable")
            if not proxy_enable:
                logging.info("ç³»ç»Ÿä»£ç†æœªå¯ç”¨")
                return None
            
            # è¯»å–ä»£ç†æœåŠ¡å™¨è®¾ç½®
            proxy_server, _ = winreg.QueryValueEx(reg_key, "ProxyServer")
            
            if proxy_server:
                # è§£æä»£ç†æœåŠ¡å™¨åœ°å€
                if "=" in proxy_server:
                    # æ ¼å¼: http=127.0.0.1:7890;https=127.0.0.1:7890
                    proxy_dict = {}
                    for item in proxy_server.split(";"):
                        if "=" in item:
                            protocol, address = item.split("=", 1)
                            proxy_dict[protocol] = f"http://{address}"
                    
                    # ç¡®ä¿è‡³å°‘æœ‰httpä»£ç†
                    if "http" not in proxy_dict and "https" in proxy_dict:
                        proxy_dict["http"] = proxy_dict["https"]
                    elif "https" not in proxy_dict and "http" in proxy_dict:
                        proxy_dict["https"] = proxy_dict["http"]
                    
                    return proxy_dict
                else:
                    # æ ¼å¼: 127.0.0.1:7890
                    proxy_url = f"http://{proxy_server}"
                    return {"http": proxy_url, "https": proxy_url}
            
        finally:
            winreg.CloseKey(reg_key)
            
    except FileNotFoundError:
        logging.info("æœªæ‰¾åˆ°ç³»ç»Ÿä»£ç†è®¾ç½®")
        return None
    except Exception as e:
        logging.warning(f"è¯»å–ç³»ç»Ÿä»£ç†è®¾ç½®å¤±è´¥: {e}")
        return None
    
    return None


def verify_proxy_twitter(proxy_dict: Dict[str, str]) -> bool:
    """
    éªŒè¯ä»£ç†æ˜¯å¦å¯ç”¨ - é€šè¿‡è¯·æ±‚æ¨ç‰¹éªŒè¯
    Args:
        proxy_dict: ä»£ç†é…ç½®å­—å…¸
    Returns:
        bool: ä»£ç†æ˜¯å¦å¯ç”¨
    """
    # ä¸»è¦çš„Twitteræµ‹è¯•URL
    main_twitter_urls = [
        "https://twitter.com",
        "https://x.com"
    ]
    
    # å¤‡ç”¨æµ‹è¯•URL
    backup_url = "https://google.com"
    
    success_count = 0
    total_main_urls = len(main_twitter_urls)
    
    # æµ‹è¯•ä¸»è¦çš„TwitteråŸŸå
    for test_url in main_twitter_urls:
        try:
            logging.info(f"å°è¯•é€šè¿‡ä»£ç†è®¿é—®: {test_url}")
            
            response = requests.get(
                test_url, 
                proxies=proxy_dict, 
                timeout=5,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                },
                allow_redirects=True
            )
            
            if response.status_code == 200:
                logging.info(f"âœ… ä»£ç†éªŒè¯æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸è®¿é—® {test_url}")
                success_count += 1
            elif response.status_code in [301, 302, 303, 307, 308]:
                # é‡å®šå‘ä¹Ÿç®—æˆåŠŸ
                logging.info(f"âœ… ä»£ç†éªŒè¯æˆåŠŸï¼Œ{test_url} è¿”å›é‡å®šå‘")
                success_count += 1
            else:
                logging.warning(f"âŒ {test_url} è¿”å›çŠ¶æ€ç : {response.status_code}")
                
        except requests.exceptions.ProxyError:
            logging.warning(f"âŒ ä»£ç†è¿æ¥å¤±è´¥: {test_url}")
        except requests.exceptions.Timeout:
            logging.warning(f"âŒ ä»£ç†è®¿é—®è¶…æ—¶: {test_url}")
        except requests.exceptions.ConnectionError:
            logging.warning(f"âŒ ä»£ç†è¿æ¥é”™è¯¯: {test_url}")
        except Exception as e:
            logging.warning(f"âŒ è®¿é—® {test_url} å¼‚å¸¸: {e}")
    
    # å¦‚æœä¸»è¦URLéƒ½æˆåŠŸï¼Œç›´æ¥è¿”å›æˆåŠŸ
    if success_count == total_main_urls:
        logging.info(f"âœ… æ‰€æœ‰ä¸»è¦TwitteråŸŸåéƒ½å¯ä»¥æ­£å¸¸è®¿é—® ({success_count}/{total_main_urls})")
        return True
    
    # å¦‚æœæœ‰éƒ¨åˆ†æˆåŠŸï¼Œä¹Ÿè®¤ä¸ºä»£ç†å¯ç”¨
    if success_count > 0:
        logging.info(f"âœ… éƒ¨åˆ†TwitteråŸŸåå¯ä»¥æ­£å¸¸è®¿é—® ({success_count}/{total_main_urls})")
        return True
    
    # å¦‚æœä¸»è¦URLéƒ½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨URL
    logging.info(f"ä¸»è¦TwitteråŸŸåéƒ½æ— æ³•è®¿é—®ï¼Œå°è¯•å¤‡ç”¨URL: {backup_url}")
    try:
        response = requests.get(
            backup_url, 
            proxies=proxy_dict, 
            timeout=5,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            },
            allow_redirects=True
        )
        
        if response.status_code == 200 or response.status_code in [301, 302, 303, 307, 308]:
            logging.info(f"âœ… å¤‡ç”¨URLéªŒè¯æˆåŠŸ: {backup_url}")
            return True
        else:
            logging.warning(f"âŒ å¤‡ç”¨URLè¿”å›çŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        logging.warning(f"âŒ å¤‡ç”¨URLè®¿é—®å¼‚å¸¸: {e}")
    
    logging.warning("âŒ æ‰€æœ‰æ¨ç‰¹URLéƒ½æ— æ³•é€šè¿‡ä»£ç†è®¿é—®")
    return False


def verify_direct_twitter_connection() -> bool:
    """
    éªŒè¯ç›´è¿ï¼ˆæ— ä»£ç†ï¼‰æ˜¯å¦å¯ä»¥è®¿é—®Twitter
    Returns:
        bool: ç›´è¿æ˜¯å¦å¯ç”¨
    """
    # ä¸»è¦çš„Twitteræµ‹è¯•URL
    main_twitter_urls = [
        "https://twitter.com",
        "https://x.com"
    ]
    
    # å¤‡ç”¨æµ‹è¯•URL
    backup_url = "https://api.twitter.com"
    
    success_count = 0
    total_main_urls = len(main_twitter_urls)
    
    # æµ‹è¯•ä¸»è¦çš„TwitteråŸŸåï¼ˆç›´è¿æ¨¡å¼ï¼‰
    for test_url in main_twitter_urls:
        try:
            logging.info(f"å°è¯•ç›´è¿è®¿é—®: {test_url}")
            
            response = requests.get(
                test_url, 
                timeout=5,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                },
                allow_redirects=True
            )
            
            if response.status_code == 200:
                logging.info(f"âœ… ç›´è¿éªŒè¯æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸è®¿é—® {test_url}")
                success_count += 1
            elif response.status_code in [301, 302, 303, 307, 308]:
                # é‡å®šå‘ä¹Ÿç®—æˆåŠŸ
                logging.info(f"âœ… ç›´è¿éªŒè¯æˆåŠŸï¼Œ{test_url} è¿”å›é‡å®šå‘")
                success_count += 1
            else:
                logging.warning(f"âŒ {test_url} è¿”å›çŠ¶æ€ç : {response.status_code}")
                
        except requests.exceptions.Timeout:
            logging.warning(f"âŒ ç›´è¿è®¿é—®è¶…æ—¶: {test_url}")
        except requests.exceptions.ConnectionError:
            logging.warning(f"âŒ ç›´è¿è¿æ¥é”™è¯¯: {test_url}")
        except Exception as e:
            logging.warning(f"âŒ ç›´è¿è®¿é—® {test_url} å¼‚å¸¸: {e}")
    
    # å¦‚æœä¸»è¦URLéƒ½æˆåŠŸï¼Œç›´æ¥è¿”å›æˆåŠŸ
    if success_count == total_main_urls:
        logging.info(f"âœ… æ‰€æœ‰ä¸»è¦TwitteråŸŸåéƒ½å¯ä»¥ç›´è¿è®¿é—® ({success_count}/{total_main_urls})")
        return True
    
    # å¦‚æœæœ‰éƒ¨åˆ†æˆåŠŸï¼Œä¹Ÿè®¤ä¸ºç›´è¿å¯ç”¨
    if success_count > 0:
        logging.info(f"âœ… éƒ¨åˆ†TwitteråŸŸåå¯ä»¥ç›´è¿è®¿é—® ({success_count}/{total_main_urls})")
        return True
    
    # å¦‚æœä¸»è¦URLéƒ½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨URL
    logging.info(f"ä¸»è¦TwitteråŸŸåéƒ½æ— æ³•ç›´è¿è®¿é—®ï¼Œå°è¯•å¤‡ç”¨URL: {backup_url}")
    try:
        response = requests.get(
            backup_url, 
            timeout=5,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            },
            allow_redirects=True
        )
        
        if response.status_code == 200 or response.status_code in [301, 302, 303, 307, 308]:
            logging.info(f"âœ… å¤‡ç”¨URLç›´è¿éªŒè¯æˆåŠŸ: {backup_url}")
            return True
        else:
            logging.warning(f"âŒ å¤‡ç”¨URLè¿”å›çŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        logging.warning(f"âŒ å¤‡ç”¨URLç›´è¿è®¿é—®å¼‚å¸¸: {e}")
    
    logging.warning("âŒ æ‰€æœ‰æ¨ç‰¹URLéƒ½æ— æ³•ç›´è¿è®¿é—®")
    return False


def setup_proxy() -> Optional[Dict[str, str]]:
    """
    è®¾ç½®ä»£ç†é…ç½®ï¼Œä½¿ç”¨æ¨ç‰¹éªŒè¯ï¼ŒåŒ…å«é™çº§å¤„ç†
    Returns:
        Dict[str, str] or None: ä»£ç†é…ç½®å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    global _global_proxy, _twitter_accessible
    
    logging.info("ğŸ” å¼€å§‹æ£€æµ‹ç³»ç»Ÿä»£ç†...")
    
    # 1. å°è¯•æ£€æµ‹ç³»ç»Ÿä»£ç†
    system_proxy = get_system_proxy()
    
    if system_proxy:
        logging.info(f"æ£€æµ‹åˆ°ç³»ç»Ÿä»£ç†: {system_proxy.get('http', 'N/A')}")
        
        # 2. ä½¿ç”¨æ¨ç‰¹éªŒè¯ä»£ç†å¯ç”¨æ€§
        if verify_proxy_twitter(system_proxy):
            logging.info("âœ… ä»£ç†éªŒè¯æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸è®¿é—®æ¨ç‰¹ï¼Œæ‰€æœ‰ç½‘ç»œè¯·æ±‚å°†ä½¿ç”¨ä»£ç†")
            _global_proxy = system_proxy
            _twitter_accessible = True
            return system_proxy
        else:
            logging.warning("âŒ ä»£ç†æ— æ³•è®¿é—®æ¨ç‰¹ï¼Œé™çº§ä¸ºç›´è¿æ¨¡å¼")
            logging.info("ğŸ” å°è¯•ç›´è¿æ¨¡å¼è®¿é—®æ¨ç‰¹...")
            
            # æµ‹è¯•ç›´è¿æ˜¯å¦èƒ½è®¿é—®Twitter
            if verify_direct_twitter_connection():
                logging.info("âœ… ç›´è¿éªŒè¯æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸è®¿é—®æ¨ç‰¹ï¼Œä½¿ç”¨ç›´è¿æ¨¡å¼")
                _global_proxy = None
                _twitter_accessible = True
                return None
            else:
                logging.warning("âŒ ç›´è¿ä¹Ÿæ— æ³•è®¿é—®æ¨ç‰¹ï¼Œç½‘ç»œè¿æ¥å¯èƒ½å­˜åœ¨é—®é¢˜")
                logging.info("âš ï¸ Twitterç²‰ä¸æ•°è·å–åŠŸèƒ½å°†è¢«ç¦ç”¨ï¼Œç¨‹åºå°†ç»§ç»­è¿è¡Œå…¶ä»–åŠŸèƒ½")
                _global_proxy = None
                _twitter_accessible = False
                return None
    else:
        logging.info("æœªæ£€æµ‹åˆ°ç³»ç»Ÿä»£ç†ï¼Œæµ‹è¯•ç›´è¿æ¨¡å¼è®¿é—®æ¨ç‰¹...")
        
        # 3. æµ‹è¯•ç›´è¿æ˜¯å¦èƒ½è®¿é—®Twitter
        if verify_direct_twitter_connection():
            logging.info("âœ… ç›´è¿éªŒè¯æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸è®¿é—®æ¨ç‰¹ï¼Œä½¿ç”¨ç›´è¿æ¨¡å¼")
            _global_proxy = None
            _twitter_accessible = True
            return None
        else:
            logging.warning("âŒ ç›´è¿æ— æ³•è®¿é—®æ¨ç‰¹ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é…ç½®ä»£ç†")
            logging.info("âš ï¸ Twitterç²‰ä¸æ•°è·å–åŠŸèƒ½å°†è¢«ç¦ç”¨ï¼Œç¨‹åºå°†ç»§ç»­è¿è¡Œå…¶ä»–åŠŸèƒ½")
            _global_proxy = None
            _twitter_accessible = False
            return None


def get_global_proxy() -> Optional[Dict[str, str]]:
    """
    è·å–å…¨å±€ä»£ç†é…ç½®
    Returns:
        Dict[str, str] or None: å…¨å±€ä»£ç†é…ç½®
    """
    return _global_proxy


def reset_proxy():
    """é‡ç½®ä»£ç†é…ç½®"""
    global _global_proxy
    _global_proxy = None


def has_proxy() -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ä»£ç†"""
    return _global_proxy is not None


def get_proxy_status() -> str:
    """è·å–ä»£ç†çŠ¶æ€æè¿°"""
    base_status = ""
    if has_proxy():
        base_status = f"ä½¿ç”¨ä»£ç†: {_global_proxy.get('http', 'N/A')}"
    else:
        base_status = "ç›´è¿æ¨¡å¼"
    
    # æ·»åŠ Twitterå¯ç”¨æ€§ä¿¡æ¯
    twitter_status = "Twitterå¯ç”¨" if _twitter_accessible else "Twitterä¸å¯ç”¨"
    return f"{base_status}, {twitter_status}"


def is_twitter_accessible() -> bool:
    """æ£€æŸ¥Twitteræ˜¯å¦å¯ç”¨"""
    return _twitter_accessible


def reset_twitter_accessibility():
    """é‡ç½®Twitterå¯ç”¨æ€§çŠ¶æ€"""
    global _twitter_accessible
    _twitter_accessible = True 