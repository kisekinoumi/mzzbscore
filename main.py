# -*- coding: utf-8 -*-
import sys
import os

# è®¾ç½®UTF-8ç¼–ç ï¼Œç¡®ä¿åœ¨exeç¯å¢ƒä¸­æ­£ç¡®å¤„ç†ä¸­æ–‡å­—ç¬¦
if sys.platform == 'win32':
    import io
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    if hasattr(sys.stderr, 'buffer'):
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONIOENCODING'] = 'utf-8'

# è¡¨æ ¼æ¨¡æ¿æ ¼å¼ï¼Œå¦‚æœä¿®æ”¹å€¼è¦æ±‚ä½¿ç”¨è€…æ›´æ–°è¡¨æ ¼æ–‡ä»¶
FORMAT_VERSION = 20250714

import time
from html import unescape

import pandas as pd
from openpyxl import load_workbook

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from models import Anime
from utils import preprocess_name, setup_logger, date_error, UrlChecker, setup_twitter_config
from utils.core.global_variables import FILE_PATH, update_constants
from utils.network import setup_proxy, get_proxy_status, is_twitter_accessible
from src.extractors import (
    extract_bangumi_data,
    extract_myanimelist_data,
    extract_anilist_data,
    extract_filmarks_data
)
from src.data_process.excel_handler import update_excel_data
from utils import ExcelColumnHelper
import concurrent.futures

# é…ç½®æ—¥å¿—
logging = setup_logger()

# ç¬¬ä¸€æ­¥ï¼šä»£ç†æ£€æµ‹å’Œé…ç½®ï¼ˆç¨‹åºè¿è¡Œçš„ç¬¬ä¸€æ­¥ï¼‰
try:
    proxy_config = setup_proxy()
    if proxy_config:
        logging.info(f"âœ… ä»£ç†é…ç½®å®Œæˆ - {get_proxy_status()}")
    else:
        logging.info(f"ğŸ“¡ ç½‘ç»œé…ç½®å®Œæˆ - {get_proxy_status()}")
except Exception as e:
    logging.error(f"ä»£ç†é…ç½®è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    logging.info("ç¨‹åºå°†ä½¿ç”¨ç›´è¿æ¨¡å¼ç»§ç»­è¿è¡Œ")

# è¾“å‡ºåˆ†éš”çº¿ï¼Œæ˜ç¡®æ ‡è¯†ä»£ç†é…ç½®å®Œæˆ
logging.info("=" * 50)

# å¼ºåˆ¶æ¸…ç©ºæ—¥æœŸé”™è¯¯åˆ—è¡¨ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½æ˜¯å¹²å‡€çš„å¼€å§‹
date_error.clear()

# é˜²æ­¢é‡å¤æ‰§è¡Œçš„æ ‡å¿—
if __name__ != "__main__":
    exit()

wb = None  # åˆå§‹åŒ–wbå˜é‡

try:
    logging.info("ç¨‹åºå¼€å§‹è¿è¡Œ...")
    
    # é…ç½®Twitterç²‰ä¸æ•°è·å–åŠŸèƒ½
    twitter_config_success = False
    
    # æ£€æŸ¥Twitteræ˜¯å¦å¯ç”¨
    if not is_twitter_accessible():
        logging.warning("Twitterç½‘ç»œä¸å¯ç”¨ï¼Œè·³è¿‡Twitterç²‰ä¸æ•°è·å–åŠŸèƒ½é…ç½®")
        twitter_config_success = False
    else:
        try:
            twitter_config_success = setup_twitter_config()
            if not twitter_config_success:
                logging.warning("Twitteré…ç½®å¤±è´¥ï¼Œå°†è·³è¿‡Twitterç²‰ä¸æ•°è·å–åŠŸèƒ½")
        except Exception as e:
            logging.error(f"Twitteré…ç½®è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            logging.info("ç¨‹åºå°†ç»§ç»­è¿è¡Œå…¶ä»–åŠŸèƒ½")
            twitter_config_success = False
    
    # ç¡®ä¿Twitteré…ç½®çš„æ‰€æœ‰è¾“å‡ºéƒ½å®Œæˆ
    import time
    time.sleep(1)
    
    # è¾“å‡ºåˆ†éš”çº¿ï¼Œæ˜ç¡®æ ‡è¯†Twitteré…ç½®å®Œæˆ
    logging.info("ğŸ“‹ å¼€å§‹å¤„ç†åŠ¨ç”»æ•°æ®...")
    
    # è¯»å–Excelæ–‡ä»¶
    try:
        wb = load_workbook(FILE_PATH)
        logging.info(f"æˆåŠŸåŠ è½½Excelæ–‡ä»¶: {FILE_PATH}")
    except Exception as e:
        logging.error(f"æ— æ³•åŠ è½½Excelæ–‡ä»¶ {FILE_PATH}: {e}")
        logging.error("è¯·æ£€æŸ¥Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
        raise
    ws = wb.active

    # æ£€æŸ¥è¡¨æ ¼æ ¼å¼ç‰ˆæœ¬
    excel_version = ws['M1'].value
    if excel_version != FORMAT_VERSION:
        logging.error(f"è¡¨æ ¼æ¨¡æ¿ç‰ˆæœ¬ä¸åŒ¹é…ï¼å½“å‰ä»£ç è¦æ±‚è¡¨æ ¼æ–‡ä»¶æ¨¡æ¿ç‰ˆæœ¬ä¸º {FORMAT_VERSION}ï¼Œä½†è¡¨æ ¼æ¨¡æ¿ç‰ˆæœ¬ä¸º {excel_version}ã€‚è¯·æ›´æ–°è¡¨æ ¼æ¨¡æ¿åé‡è¯•ã€‚")
        raise SystemExit(1)

    # æ›´æ–°å…¨å±€å¸¸é‡
    update_constants(str(ws['A1'].value)[:4])  # è¯»å–è¡¨æ ¼è®¾ç½®ç›®æ ‡æ”¾é€å¹´ä»½

    df = pd.read_excel(FILE_PATH, skiprows=1)
    
    # æ¸…ç©ºæ—¥æœŸé”™è¯¯åˆ—è¡¨ï¼Œé¿å…é‡å¤ç´¯ç§¯
    date_error.clear()
    
    # åˆ›å»ºExcelåˆ—åŠ©æ‰‹ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼Œé¿å…é‡å¤è¾“å‡ºæ˜ å°„æ—¥å¿—ï¼‰
    col_helper = ExcelColumnHelper(ws)
    
    # éå†DataFrameä¸­çš„æ¯ä¸€è¡Œæ•°æ®
    for index, row in df.iterrows():
        if pd.isna(row['åŸå']):
            logging.warning(f"Skipping row {index} because the original name is NaN.")
            continue  # è·³è¿‡è¿™ä¸€è¡Œ
        
        anime = Anime(original_name=row['åŸå'])  # è·å–æ¯è¡Œçš„"åŸå"åˆ—ä½œä¸ºåŸå§‹åç§°
        logging.info(str(anime))
        
        # è·å–å½“å‰è¡Œçš„Excelè¡Œå¯¹è±¡ç”¨äºé“¾æ¥æ£€æŸ¥
        excel_row = ws[index + 3]  # DataFrameä»0å¼€å§‹ï¼ŒExcelä»1å¼€å§‹ï¼Œä¸”æœ‰è¡¨å¤´ï¼Œæ‰€ä»¥+3
        
        # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦å·²æœ‰é“¾æ¥æ•°æ®
        existing_urls = UrlChecker.check_row_urls(excel_row, col_helper)
        
        # å¦‚æœæ‰¾åˆ°é“¾æ¥ï¼Œé¢„å…ˆè®¾ç½®åˆ°animeå¯¹è±¡ä¸­
        if existing_urls['bangumi']:
            anime.bangumi_url = existing_urls['bangumi']
        if existing_urls['anilist']:
            anime.anilist_url = existing_urls['anilist']
        if existing_urls['myanimelist']:
            anime.myanimelist_url = existing_urls['myanimelist']
        if existing_urls['filmarks']:
            anime.filmarks_url = existing_urls['filmarks']
        
        # åˆ¤æ–­æ˜¯å¦æœ‰ä»»ä½•ç°æœ‰é“¾æ¥
        has_existing_links = UrlChecker.has_any_url(existing_urls)
        available_platforms = UrlChecker.get_available_platforms(existing_urls)
        
        if has_existing_links:
            logging.info(f"å‘ç°å·²æœ‰é“¾æ¥çš„å¹³å°: {', '.join(available_platforms)}")
        else:
            logging.info("æœªå‘ç°å·²æœ‰é“¾æ¥ï¼Œå°†è¿›è¡Œæœç´¢æ¨¡å¼")
        
        # é¢„å¤„ç†åç§°ï¼ˆä»ç„¶éœ€è¦ï¼Œç”¨äºæ²¡æœ‰é“¾æ¥çš„å¹³å°ï¼‰
        processed_name = preprocess_name(anime.original_name)

        # æå–æ•°æ® - å¹¶å‘æ‰§è¡Œ
        # åŸå§‹çš„ä¸²è¡Œæ‰§è¡Œä»£ç ï¼ˆæ³¨é‡Šæ‰ï¼‰
        # extract_bangumi_data(anime, processed_name)
        # extract_myanimelist_data(anime, processed_name)
        # extract_anilist_data(anime, processed_name)
        # extract_filmarks_data(anime, processed_name)
        
        # åˆ›å»ºçº¿ç¨‹æ± æ‰§è¡Œå™¨
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
            future_to_extractor = {
                executor.submit(extract_bangumi_data, anime, processed_name): "bangumi",
                executor.submit(extract_myanimelist_data, anime, processed_name): "myanimelist",
                executor.submit(extract_anilist_data, anime, processed_name): "anilist",
                executor.submit(extract_filmarks_data, anime, processed_name): "filmarks"
            }
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in concurrent.futures.as_completed(future_to_extractor):
                extractor_name = future_to_extractor[future]
                try:
                    result = future.result()
                    logging.info(f"{extractor_name} extractor completed")
                except Exception as exc:
                    logging.error(f"{extractor_name} extractor generated an exception: {exc}")

        # å¦‚æœ MAL æ²¡æœ‰æ‰¾åˆ°å€™é€‰æ¡ç›®ï¼Œä½† AniList æœåˆ°åç§°ï¼Œåˆ™ç”¨ AniList è¿”å›çš„åç§°é‡æ–°æœç´¢ MAL
        mal_not_found = anime.score_mal in ["No acceptable subject found", "No results found"]
        if mal_not_found and anime.anilist_name:
            logging.info("MALå€™é€‰æœªæ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ AniList è¿”å›çš„åç§°é‡æ–°æœç´¢ MAL")
            new_processed_name = preprocess_name(anime.anilist_name)
            extract_myanimelist_data(anime, new_processed_name)
        # å¦‚æœ AniList æ²¡æœ‰æ‰¾åˆ°å€™é€‰æ¡ç›®ï¼Œä½† MAL æœåˆ°åç§°ï¼Œåˆ™ç”¨ MAL è¿”å›çš„åç§°é‡æ–°æœç´¢ AniList
        anilist_not_found = anime.score_al in ["No acceptable subject found", "No AniList results"]
        if anilist_not_found and anime.myanimelist_name:
            logging.info("AniListå€™é€‰æœªæ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨ MAL è¿”å›çš„åç§°é‡æ–°æœç´¢ AniList")
            new_processed_name = unescape(preprocess_name(anime.myanimelist_name))
            extract_anilist_data(anime, new_processed_name)


        # è·å–Twitterç²‰ä¸æ•°ï¼ˆå¦‚æœæ‰¾åˆ°äº†Twitterè´¦å·ä¸”é…ç½®æˆåŠŸä¸”ç½‘ç»œå¯ç”¨ï¼‰
        if hasattr(anime, 'twitter_username') and anime.twitter_username:
            if not is_twitter_accessible():
                logging.info(f"å‘ç°Twitterè´¦å· @{anime.twitter_username}ï¼Œä½†Twitterç½‘ç»œä¸å¯ç”¨ï¼Œè·³è¿‡ç²‰ä¸æ•°è·å–")
                anime.twitter_followers = "ç½‘ç»œä¸å¯ç”¨"
            elif twitter_config_success:
                try:
                    from src.extractors import TwitterFollowersHelper
                    followers_count = TwitterFollowersHelper.get_followers_count(anime.twitter_username)
                    if followers_count is not None:
                        anime.twitter_followers = followers_count
                    else:
                        logging.warning(f"æ— æ³•è·å– @{anime.twitter_username} çš„ç²‰ä¸æ•°")
                        anime.twitter_followers = "è·å–å¤±è´¥"
                except Exception as e:
                    logging.error(f"è·å–Twitterç²‰ä¸æ•°æ—¶å‡ºé”™: {e}")
                    anime.twitter_followers = "è·å–å‡ºé”™"
            else:
                logging.info(f"å‘ç°Twitterè´¦å· @{anime.twitter_username}ï¼Œä½†Twitteré…ç½®æœªæˆåŠŸï¼Œè·³è¿‡ç²‰ä¸æ•°è·å–")
                anime.twitter_followers = "é…ç½®æœªæˆåŠŸ"

        # æ›´æ–°Excelæ•°æ®
        update_excel_data(ws, index, anime, col_helper)

        # å»¶æ—¶ä»¥é¿å…é¢‘ç¹è¯·æ±‚è¢«æ‹’ç»
        time.sleep(0.1)

except Exception as e:
    logging.error(f"å‘ç”Ÿé”™è¯¯: {e}")

finally:
    # ä¿å­˜Excelæ–‡ä»¶
    if wb is not None:
        try:
            wb.save(FILE_PATH)
            logging.info("Excelè¡¨æ ¼å·²æˆåŠŸæ›´æ–°ã€‚")
        except Exception as e:
            logging.error(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    else:
        logging.warning("Excelæ–‡ä»¶æœªæˆåŠŸåŠ è½½ï¼Œè·³è¿‡ä¿å­˜æ“ä½œ")
    
    # è¾“å‡ºæ—¥æœŸé”™è¯¯ä¿¡æ¯
    try:
        if date_error:
            logging.info("\n" + "=" * 50)
            logging.info("æ—¥æœŸé”™è¯¯æ±‡æ€» (å…± %d æ¡):" % len(date_error))
            logging.info("=" * 50)
            for i, error in enumerate(date_error, 1):
                logging.info("%d. ä½œå“ï¼š%s" % (i, error["name"]))
                logging.info("   é”™è¯¯ï¼š%s" % error["error"])
                logging.info("-" * 50)
        else:
            logging.info("æ²¡æœ‰å‘ç°ä»»ä½•æ—¥æœŸé”™è¯¯ï¼")
    except Exception as e:
        logging.error(f"è¾“å‡ºæ—¥æœŸé”™è¯¯ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    # ç­‰å¾…ç”¨æˆ·è¾“å…¥é€€å‡º
    try:
        while True:
            user_input = input("è¾“å…¥ 'exit' é€€å‡ºç¨‹åº: ")
            if user_input.lower() == 'exit':  # å¿½ç•¥å¤§å°å†™ï¼Œå…è®¸ 'exit' é€€å‡º
                break
        logging.info("ç¨‹åºå·²é€€å‡º...")
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­...")
    except Exception as e:
        logging.error(f"é€€å‡ºå¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        logging.info("ç¨‹åºå¼‚å¸¸é€€å‡º...")